{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/causality-guided-Transformer/PAIN_Main_MAVEN_ERE.py \\\n",
    " -data /content/drive/MyDrive/causality-guided-Transformer/data/MAVEN_ERE/  \\\n",
    " -prior /content/drive/MyDrive/causality-guided-Transformer/prior/MAVEN_ERE/sparse/ \\\n",
    " -epoch 1\\\n",
    " -batch_size 16\\\n",
    " -d_model 512 \\\n",
    " -d_inner 256 \\\n",
    " -d_k 256 \\\n",
    " -d_v 256 \\\n",
    " -n_head 4 \\\n",
    " -n_layers 4 \\\n",
    " -dropout 0.1 \\\n",
    " -lr 1e-4 \\\n",
    " -num_samples 1 \\\n",
    " -event_interest 7 \\\n",
    " -threshold 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import subprocess\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "drive_folder = '/content/drive/MyDrive/PAIN_results/'\n",
    "os.makedirs(drive_folder, exist_ok=True)\n",
    "csv_file = 'PAIN_fine_tuning_loglikelihood_results.csv'\n",
    "drive_csv_path = os.path.join(drive_folder, csv_file)\n",
    "\n",
    "if not os.path.exists(csv_file):\n",
    "    columns = [\n",
    "        'epoch', 'batch_size', 'd_model', 'd_inner', 'd_k', 'd_v', 'n_head',\n",
    "        'n_layers', 'dropout', 'lr', 'num_samples', 'event_interest',\n",
    "        'threshold', 'val_loglikelihood'\n",
    "    ]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    shutil.copy(csv_file, drive_csv_path)\n",
    "\n",
    "def save_to_drive():\n",
    "    shutil.copy(csv_file, drive_csv_path)\n",
    "    print(f\"Updated {csv_file} saved to Google Drive at {drive_csv_path}.\")\n",
    "\n",
    "def fine_tune_model(epoch, batch_size, d_model, d_inner, d_k, d_v, n_head,\n",
    "                    n_layers, dropout, lr, num_samples, event_interest, threshold):\n",
    "    print(f\"Running fine-tuning with parameters: \"\n",
    "          f\"epoch={epoch}, batch_size={batch_size}, d_model={d_model}, \"\n",
    "          f\"d_inner={d_inner}, d_k={d_k}, d_v={d_v}, n_head={n_head}, n_layers={n_layers}, \"\n",
    "          f\"dropout={dropout}, lr={lr}, num_samples={num_samples}, \"\n",
    "          f\"event_interest={event_interest}, threshold={threshold}\")\n",
    "\n",
    "    def run_command(command):\n",
    "        print(f\"Running command: {' '.join(command)}\")\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        output = result.stdout\n",
    "        return output\n",
    "\n",
    "    command = [\n",
    "        'python', '/content/drive/MyDrive/causality-guided-Transformer/PAIN_Main_MAVEN_ERE.py',\n",
    "        '-data', '/content/drive/MyDrive/causality-guided-Transformer/data/MAVEN_ERE/',\n",
    "        '-prior', '/content/drive/MyDrive/causality-guided-Transformer/prior/MAVEN_ERE/sparse/',\n",
    "        '-epoch', str(epoch),\n",
    "        '-batch_size', str(batch_size),\n",
    "        '-d_model', str(d_model),\n",
    "        '-d_inner', str(d_inner),\n",
    "        '-d_k', str(d_k),\n",
    "        '-d_v', str(d_v),\n",
    "        '-n_head', str(n_head),\n",
    "        '-n_layers', str(n_layers),\n",
    "        '-dropout', str(dropout),\n",
    "        '-lr', str(lr),\n",
    "        '-num_samples', str(num_samples),\n",
    "        '-event_interest', str(event_interest),\n",
    "        '-threshold', str(threshold)\n",
    "    ]\n",
    "\n",
    "    output = run_command(command)\n",
    "\n",
    "    train_loglikelihood = None\n",
    "    val_loglikelihood = None\n",
    "    test_loglikelihood = None\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if '(Training)' in line:\n",
    "            train_loglikelihood = float(line.split('loglikelihood:')[-1].split(',')[0].strip())\n",
    "        elif '(Validation)' in line:\n",
    "            val_loglikelihood = float(line.split('loglikelihood:')[-1].split(',')[0].strip())\n",
    "        elif '(Test)' in line:\n",
    "            test_loglikelihood = float(line.split('loglikelihood:')[-1].split(',')[0].strip())\n",
    "\n",
    "    return val_loglikelihood\n",
    "\n",
    "def objective(trial):\n",
    "    epoch = trial.suggest_categorical('epoch', [5, 10, 20])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    d_model = trial.suggest_categorical('d_model', [64, 128, 256])\n",
    "    d_inner = trial.suggest_categorical('d_inner', [128, 256, 512])\n",
    "    d_k = trial.suggest_categorical('d_k', [32, 64, 128])\n",
    "    d_v = trial.suggest_categorical('d_v', [32, 64, 128])\n",
    "    n_head = trial.suggest_categorical('n_head', [2, 4, 8])\n",
    "    n_layers = trial.suggest_categorical('n_layers', [2, 4, 6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 5e-4)\n",
    "    num_samples = trial.suggest_categorical('num_samples', [1, 5, 10])\n",
    "    event_interest = trial.suggest_categorical('event_interest', [7])\n",
    "    threshold = trial.suggest_float('threshold', 0.2, 0.5)\n",
    "\n",
    "    val_loglikelihood = fine_tune_model(epoch, batch_size,\n",
    "                                        d_model, d_inner,\n",
    "                                        d_k, d_v, n_head,\n",
    "                                        n_layers, dropout,\n",
    "                                        lr, num_samples,\n",
    "                                        event_interest,\n",
    "                                        threshold)\n",
    "\n",
    "    trial_result = {\n",
    "        'epoch': epoch,\n",
    "        'batch_size': batch_size,\n",
    "        'd_model': d_model,\n",
    "        'd_inner': d_inner,\n",
    "        'd_k': d_k,\n",
    "        'd_v': d_v,\n",
    "        'n_head': n_head,\n",
    "        'n_layers': n_layers,\n",
    "        'dropout': dropout,\n",
    "        'lr': lr,\n",
    "        'num_samples': num_samples,\n",
    "        'event_interest': event_interest,\n",
    "        'threshold': threshold,\n",
    "        'val_loglikelihood': val_loglikelihood\n",
    "    }\n",
    "    trial_df = pd.DataFrame([trial_result])\n",
    "    trial_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "\n",
    "    save_to_drive()\n",
    "\n",
    "    return val_loglikelihood\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loglikelihood:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
