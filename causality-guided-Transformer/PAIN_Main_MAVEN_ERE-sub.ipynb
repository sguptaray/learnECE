{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/causality-guided-Transformer/PAIN_Main_MAVEN_ERE.py \\\n",
    " -data /content/drive/MyDrive/causality-guided-Transformer/data/MAVEN_ERE/  \\\n",
    " -prior /content/drive/MyDrive/causality-guided-Transformer/prior/MAVEN_ERE/sparse/ \\\n",
    " -epoch 1\\\n",
    " -batch_size 16\\\n",
    " -d_model 512 \\\n",
    " -d_inner 256 \\\n",
    " -d_k 256 \\\n",
    " -d_v 256 \\\n",
    " -n_head 4 \\\n",
    " -n_layers 4 \\\n",
    " -dropout 0.1 \\\n",
    " -lr 1e-4 \\\n",
    " -num_samples 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "def fine_tune_model(epoch, batch_size, d_model, d_inner, d_k, d_v, n_head, n_layers, dropout, lr, num_samples, total_epochs):\n",
    "    print(f\"Running fine-tuning with parameters: \"\n",
    "          f\"epoch={epoch}, batch_size={batch_size}, d_model={d_model}, \"\n",
    "          f\"d_inner={d_inner}, d_k={d_k}, d_v={d_v}, n_head={n_head}, n_layers={n_layers}, \"\n",
    "          f\"dropout={dropout}, lr={lr}, num_samples={num_samples}\")\n",
    "\n",
    "    train_loglikelihood = None\n",
    "    val_loglikelihood = None\n",
    "    test_loglikelihood = None\n",
    "\n",
    "    def run_command(command):\n",
    "        print(f\"Running command: {' '.join(command)}\")\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        output = result.stdout\n",
    "        print(result.stdout)\n",
    "        return output\n",
    "\n",
    "    for i in range(total_epochs):\n",
    "        print(f\"[Epoch {i+1}/{total_epochs}] Starting fine-tuning...\")\n",
    "\n",
    "        command = [\n",
    "            'python', '/content/drive/MyDrive/causality-guided-Transformer/PAIN_Main_MAVEN_ERE.py',\n",
    "            '-data', '/content/drive/MyDrive/causality-guided-Transformer/data/MAVEN_ERE/',\n",
    "            '-prior', '/content/drive/MyDrive/causality-guided-Transformer/prior/MAVEN_ERE/sparse/',\n",
    "            '-epoch', str(epoch),\n",
    "            '-batch_size', str(batch_size),\n",
    "            '-d_model', str(d_model),\n",
    "            '-d_inner', str(d_inner),\n",
    "            '-d_k', str(d_k),\n",
    "            '-d_v', str(d_v),\n",
    "            '-n_head', str(n_head),\n",
    "            '-n_layers', str(n_layers),\n",
    "            '-dropout', str(dropout),\n",
    "            '-lr', str(lr),\n",
    "            '-num_samples', str(num_samples)\n",
    "        ]\n",
    "\n",
    "        output = run_command(command)\n",
    "\n",
    "        for line in output.splitlines():\n",
    "            if '(Training)' in line:\n",
    "                train_loglikelihood = float(line.split('loglikelihood:')[-1].split(',')[0].strip())\n",
    "                # print(f\"[ Epoch {i+1} ] - (Training) loglikelihood: {train_loglikelihood:.4f}\")\n",
    "\n",
    "            elif '(Validation)' in line:\n",
    "                val_loglikelihood = float(line.split('loglikelihood:')[-1].split(',')[0].strip())\n",
    "                # print(f\"[ Epoch {i+1} ] - (Validation) loglikelihood: {val_loglikelihood:.4f}\")\n",
    "\n",
    "            elif '(Test)' in line:\n",
    "                test_loglikelihood = float(line.split('loglikelihood:')[-1].split(',')[0].strip())\n",
    "                # print(f\"[ Epoch {i+1} ] - (Test) loglikelihood: {test_loglikelihood:.4f}\")\n",
    "\n",
    "        print(f\"[ Epoch {i+1} ] - [Info] Maximum validation loglikelihood: {val_loglikelihood:.4f}\")\n",
    "        print(f\"Test log likelihood is {test_loglikelihood:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'epoch': epoch,\n",
    "        'batch_size': batch_size,\n",
    "        'd_model': d_model,\n",
    "        'd_inner': d_inner,\n",
    "        'd_k': d_k,\n",
    "        'd_v': d_v,\n",
    "        'n_head': n_head,\n",
    "        'n_layers': n_layers,\n",
    "        'dropout': dropout,\n",
    "        'lr': lr,\n",
    "        'num_samples': num_samples,\n",
    "        'train_loglikelihood': train_loglikelihood,\n",
    "        'val_loglikelihood': val_loglikelihood,\n",
    "        'test_loglikelihood': test_loglikelihood\n",
    "    }\n",
    "\n",
    "epochs = [1, 3, 5]\n",
    "batch_sizes = [32, 64, 128]\n",
    "d_models = [256, 512, 1024]\n",
    "d_inners = [128, 256, 512]\n",
    "d_ks = [128, 256]\n",
    "d_vs = [128, 256]\n",
    "n_heads = [2, 4, 8]\n",
    "n_layers = [2, 4, 6]\n",
    "dropouts = [0.1, 0.2, 0.3]\n",
    "lrs = [1e-4, 1e-5, 1e-3]\n",
    "num_samples_list = [1, 3, 5]\n",
    "\n",
    "\n",
    "hyperparameter_combinations = list(product(epochs,\n",
    "                                           batch_sizes,\n",
    "                                           d_models,\n",
    "                                           d_inners,\n",
    "                                           d_ks,\n",
    "                                           d_vs,\n",
    "                                           n_heads,\n",
    "                                           n_layers,\n",
    "                                           dropouts,\n",
    "                                           lrs,\n",
    "                                           num_samples_list))\n",
    "\n",
    "results = []\n",
    "for params in hyperparameter_combinations:\n",
    "    print(f\"Now running model with hyperparameters: {params}\")\n",
    "    result = fine_tune_model(*params, total_epochs=params[0])\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('PAIN_fine_tuning_loglikelihood_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
